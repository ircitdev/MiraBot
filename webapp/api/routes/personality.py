"""
Personality Analysis API endpoints.
"""

import io
from datetime import datetime, timedelta
from fastapi import APIRouter, Depends, HTTPException
from fastapi.responses import StreamingResponse
from loguru import logger

from webapp.api.auth import get_current_user
from database.repositories.user import UserRepository
from database.repositories.conversation import ConversationRepository
from database.repositories.user_report import UserReportRepository
from database.repositories.api_cost import ApiCostRepository
from config.settings import settings


router = APIRouter()
user_repo = UserRepository()
conv_repo = ConversationRepository()
report_repo = UserReportRepository()
api_cost_repo = ApiCostRepository()


@router.post("/analysis")
async def generate_personality_analysis(current_user: dict = Depends(get_current_user)):
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∞–Ω–∞–ª–∏–∑ –ª–∏—á–Ω–æ—Å—Ç–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤—Å–µ–π –ø–µ—Ä–µ–ø–∏—Å–∫–∏.

    –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:
    - Premium –ø–æ–¥–ø–∏—Å–∫–∞
    - –ú–∏–Ω–∏–º—É–º 20 —Å–æ–æ–±—â–µ–Ω–∏–π
    - –ú–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å 1 —Ä–∞–∑ –≤ –º–µ—Å—è—Ü
    """
    user = await user_repo.get_by_telegram_id(current_user["user_id"])

    if not user:
        raise HTTPException(status_code=404, detail="User not found")

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ Premium —Å—Ç–∞—Ç—É—Å–∞
    if not user.premium_until or user.premium_until < datetime.utcnow():
        raise HTTPException(
            status_code=403,
            detail="–ê–Ω–∞–ª–∏–∑ –ª–∏—á–Ω–æ—Å—Ç–∏ –¥–æ—Å—Ç—É–ø–µ–Ω —Ç–æ–ª—å–∫–æ –¥–ª—è Premium –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π"
        )

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å–æ–æ–±—â–µ–Ω–∏–π
    messages, total = await conv_repo.get_paginated(user.id, page=1, per_page=20)

    if total < 20:
        raise HTTPException(
            status_code=400,
            detail="–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞. –ü–æ–æ–±—â–∞–π—Å—è —Å–æ –º–Ω–æ–π –±–æ–ª—å—à–µ! (–º–∏–Ω–∏–º—É–º 20 —Å–æ–æ–±—â–µ–Ω–∏–π)"
        )

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ (—Ä–∞–∑ –≤ –º–µ—Å—è—Ü)
    from database.models import UserReport
    from database.base import get_session_context
    from sqlalchemy import select, and_

    async with get_session_context() as session:
        one_month_ago = datetime.utcnow() - timedelta(days=30)
        query = select(UserReport).where(
            and_(
                UserReport.telegram_id == user.telegram_id,
                UserReport.created_at >= one_month_ago
            )
        ).order_by(UserReport.created_at.desc())

        result = await session.execute(query)
        recent_report = result.scalar_one_or_none()

        if recent_report:
            days_left = 30 - (datetime.utcnow() - recent_report.created_at).days
            raise HTTPException(
                status_code=429,
                detail=f"–ê–Ω–∞–ª–∏–∑ –ª–∏—á–Ω–æ—Å—Ç–∏ –¥–æ—Å—Ç—É–ø–µ–Ω —Ä–∞–∑ –≤ –º–µ—Å—è—Ü. –°–ª–µ–¥—É—é—â–∏–π –∞–Ω–∞–ª–∏–∑ –±—É–¥–µ—Ç –¥–æ—Å—Ç—É–ø–µ–Ω —á–µ—Ä–µ–∑ {days_left} –¥–Ω–µ–π."
            )

    # –ü–æ–ª—É—á–∞–µ–º –í–°–ï —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    all_messages, total_count = await conv_repo.get_paginated(user.id, page=1, per_page=5000)

    if not all_messages:
        raise HTTPException(status_code=400, detail="–ù–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")

    # –§–æ—Ä–º–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç –ø–µ—Ä–µ–ø–∏—Å–∫–∏
    conversation_text = []
    for msg in reversed(all_messages):  # –û—Ç —Å—Ç–∞—Ä—ã—Ö –∫ –Ω–æ–≤—ã–º
        role = "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å" if msg.role == "user" else "–ú–∏—Ä–∞"
        date = msg.created_at.strftime("%d.%m.%Y %H:%M")
        conversation_text.append(f"[{date}] {role}: {msg.content}")

    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä (–º–∞–∫—Å 100K —Å–∏–º–≤–æ–ª–æ–≤)
    full_text = "\n".join(conversation_text)
    if len(full_text) > 100000:
        full_text = full_text[-100000:]

    # –ò–º—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    user_name = user.display_name or user.first_name or f"ID:{user.telegram_id}"

    # –ü—Ä–æ–º–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ª–∏—á–Ω–æ—Å—Ç–∏
    analysis_prompt = f"""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –ø–µ—Ä–µ–ø–∏—Å–∫—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Å AI-–ø–æ–¥—Ä—É–≥–æ–π –ú–∏—Ä–æ–π –∏ —Å–æ–∑–¥–∞–π –≥–ª—É–±–æ–∫–∏–π –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –ø—Ä–æ—Ñ–∏–ª—å.

–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {user_name}

–°–æ–∑–¥–∞–π –¥–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á—ë—Ç –≤ Markdown —Ñ–æ—Ä–º–∞—Ç–µ:

# –ê–Ω–∞–ª–∏–∑ –ª–∏—á–Ω–æ—Å—Ç–∏: {user_name}

## üé≠ –ö—Ç–æ —è?
[–ì–ª—É–±–∏–Ω–Ω–∞—è —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞ –ª–∏—á–Ω–æ—Å—Ç–∏, —Ü–µ–Ω–Ω–æ—Å—Ç–∏, –º–æ—Ç–∏–≤–∞—Ü–∏—è, –∂–∏–∑–Ω–µ–Ω–Ω–∞—è –ø–æ–∑–∏—Ü–∏—è]

## üí≠ –û —á—ë–º —è –¥—É–º–∞—é
[–û—Å–Ω–æ–≤–Ω—ã–µ —Ç–µ–º—ã –ø–µ—Ä–µ–∂–∏–≤–∞–Ω–∏–π, –≤–æ–ª–Ω—É—é—â–∏–µ –≤–æ–ø—Ä–æ—Å—ã, –∏–Ω—Ç–µ—Ä–µ—Å—ã]

## üòä –ú–æ–π —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –º–∏—Ä
[–≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω, –∫–∞–∫ —Ä–µ–∞–≥–∏—Ä—É—é –Ω–∞ —Å–æ–±—ã—Ç–∏—è, —á—Ç–æ –º–µ–Ω—è —Ä–∞–¥—É–µ—Ç/—Ä–∞—Å—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç]

## ‚ö° –ú–æ–∏ —Å–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã
[–ö–∞—á–µ—Å—Ç–≤–∞, —Ä–µ—Å—É—Ä—Å—ã, —Ç–æ –≤ —á—ë–º —è —Ö–æ—Ä–æ—à/—Ö–æ—Ä–æ—à–∞]

## üîç –¢–æ—á–∫–∏ —Ä–æ—Å—Ç–∞
[–ß—Ç–æ —Å—Ç–æ–∏—Ç —Ä–∞–∑–≤–∏—Ç—å, –Ω–∞–¥ —á–µ–º –ø–æ—Ä–∞–±–æ—Ç–∞—Ç—å - –¥–µ–ª–∏–∫–∞—Ç–Ω–æ –∏ —Å –∑–∞–±–æ—Ç–æ–π]

## üå± –ú–æ–π –ø—Ä–æ–≥—Ä–µ—Å—Å
[–ö–∞–∫ –º–µ–Ω—è–ª–∞—Å—å —Å –Ω–∞—á–∞–ª–∞ –æ–±—â–µ–Ω–∏—è, –∫–∞–∫–∏–µ –µ—Å—Ç—å –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–µ —Å–¥–≤–∏–≥–∏]

## üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è —Å–µ–±—è
[–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Å–æ–≤–µ—Ç—ã –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∂–∏–∑–Ω–∏, –æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–µ –Ω–∞ –≤—ã—è–≤–ª–µ–Ω–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–∞—Ö]

## üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
- –î–∞—Ç–∞ –ø–µ—Ä–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è: [–¥–∞—Ç–∞]
- –í—Å–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏–π: {total_count}
- –ü–µ—Ä–∏–æ–¥ –æ–±—â–µ–Ω–∏—è: [–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π]

---
*–≠—Ç–æ—Ç –∞–Ω–∞–ª–∏–∑ —Å–æ–∑–¥–∞–Ω –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–∞—à–µ–π –ø–µ—Ä–µ–ø–∏—Å–∫–∏ —Å –ú–∏—Ä–æ–π. –û–Ω –æ—Ç—Ä–∞–∂–∞–µ—Ç –≤–∞—à –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π –º–∏—Ä —Ç–∞–∫–∏–º, –∫–∞–∫–∏–º –≤—ã –µ–≥–æ –ø–æ–∫–∞–∑–∞–ª–∏.*

–ü–∏—à–∏ –æ—Ç –ª–∏—Ü–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è ("—è", "–º–Ω–µ"), —Ç–µ–ø–ª–æ –∏ —Å –∑–∞–±–æ—Ç–æ–π. –ò—Å–ø–æ–ª—å–∑—É–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã –∏–∑ –ø–µ—Ä–µ–ø–∏—Å–∫–∏.

–ü–ï–†–ï–ü–ò–°–ö–ê:
{full_text}"""

    try:
        # –°–æ–∑–¥–∞—ë–º –∫–ª–∏–µ–Ω—Ç Anthropic
        import anthropic
        client = anthropic.Anthropic(api_key=settings.ANTHROPIC_API_KEY)

        # –ó–∞–ø—Ä–æ—Å –∫ Claude
        response = client.messages.create(
            model="claude-sonnet-4-20250514",
            max_tokens=3000,
            messages=[
                {"role": "user", "content": analysis_prompt}
            ]
        )

        analysis_text = response.content[0].text

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–æ–∫–µ–Ω–∞—Ö
        tokens_used = response.usage.input_tokens + response.usage.output_tokens

        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–æ–∏–º–æ—Å—Ç—å
        input_cost = (response.usage.input_tokens / 1_000_000) * 3.0
        output_cost = (response.usage.output_tokens / 1_000_000) * 15.0
        cost_usd = round(input_cost + output_cost, 6)

        # –¢—Ä–µ–∫–∞–µ–º —Å—Ç–æ–∏–º–æ—Å—Ç—å API
        await api_cost_repo.create(
            user_id=user.id,
            provider='claude',
            operation='personality_analysis',
            cost_usd=cost_usd,
            input_tokens=response.usage.input_tokens,
            output_tokens=response.usage.output_tokens,
            total_tokens=tokens_used,
            model="claude-sonnet-4-20250514",
        )

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á—ë—Ç –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
        await report_repo.create(
            telegram_id=user.telegram_id,
            content=analysis_text,
            created_by=None,  # –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º
            tokens_used=tokens_used,
            cost_usd=cost_usd,
        )

        logger.info(f"Personality analysis generated for user {user.telegram_id}, cost: ${cost_usd}")

    except Exception as e:
        logger.error(f"Failed to generate personality analysis: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞–Ω–∞–ª–∏–∑–∞: {str(e)}"
        )

    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º Markdown —Ñ–∞–π–ª
    output = io.BytesIO(analysis_text.encode('utf-8'))

    return StreamingResponse(
        output,
        media_type="text/markdown",
        headers={
            "Content-Disposition": f"attachment; filename=mira_personality_analysis_{user.telegram_id}.md"
        }
    )
